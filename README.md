# Leveraging Pre-trained Large Language Models to Construct and Utilize World Models for Model-based Task Planning

Python implementation of the paper: [Leveraging Pre-trained Large Language Models to Construct and Utilize World Models for Model-based Task Planning](https://guansuns.github.io/pages/llm-dm).

**Note**: The code has been refactored for better readability. If you encounter any problem, feel free to email lguan9@asu.edu.

### Step 1. Generate World (Domain) Models

To leverage an LLM to construct a domain model, you need to provide the following information:
- Natural language descriptions of all the actions. Example: `prompts/logistics/action_model.json`.
- A description of the domain. Example: `prompts/logistics/domain_desc.txt`.
- Information of the object types and hierarchy. Example: `prompts/logistics/hierarchy_requirements.json`.

Then, in the script `construct_action_models.py`, specify the domain and the LLM model (and other configurations if needed). When this script is executed, the LLM will generate PDDL models for all actions in turn. As mentioned in the paper (Appendix), we have implemented a simple PDDL syntax validator (`pddl_syntax_validator.py`) in Python. Although it does not comprehensively cover all errors in PDDL, we found it sufficient to correct basic syntax errors in models generated by GPT-4.

The experiment record, the generated PDDL model and the translated PDDL will be saved under the directory `results/{domain}/model_blocksworld/` (note: `model_blocksworld` means that the default prompt uses the Blocksworld as examples). Then the domain expert can inspect the action models and provide corrective feedback as needed. The feedback messages should be provided under the `annotation` list of each action in the file `{llm-model}_pddl_for_annotations.json`.

### Step 2. Correct World (Domain) Models

While it may be easy for PDDL experts to directly inspect and correct the generated PDDL models, we cannot assume that all end users possess this level of expertise. The script `correct_action_models.py` implements a pipeline that involves reading natural language feedback in `{llm-model}_pddl_for_annotations.json`, replaying and continuing the PDDL-construction dialogue, and obtaining the corrected domain model from the LLM. Similar to the generation script, here we need to specify the domain and the LLM model (and other configurations if needed). The experiment record, the final PDDL model and the final predicate list will be saved under the sub-directory `corrected`.

**Note**: Step 1 and Step 2 are the core components of the solutions discussed in the original paper . We plan to provide a reference implementation of the complete planning pipeline at a later time.

### Examples
We provide the constructed models for two IPC domains (i.e., logistics and tyreworld) as examples (the results were obtained on 06/03/23). The experiment records and models are located in the `results` directory.

